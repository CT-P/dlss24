{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dcDm6T3HaRYG"},"outputs":[],"source":["#Import drive\n","from google.colab import drive\n","#Mount Google Drive\n","ROOT=\"/content/drive\"\n","drive.mount(ROOT, force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Zxub8uiRF7M"},"outputs":[],"source":["%pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajyqZyUQRLdL"},"outputs":[],"source":["%cd /content/drive/MyDrive/dlss24"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LTf-v1gWRNv2"},"outputs":[],"source":["%pwd"]},{"cell_type":"markdown","metadata":{"id":"4lnmzacMRV9e"},"source":["# Data\n","\n","Download the corpora data from: https://codeocean.com/capsule/0078777/tree/v1\n","\n","Uploaded to a location outside your gitHub (to do not be tracked)\n","\n","You pwd should have the files:\n","\n","\n","1.   source_corpus.csv\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BE3M-5mHbRdU"},"source":["\n","# Module IV:  - Class 7 - Text Classifiers\n","\n"]},{"cell_type":"markdown","metadata":{"id":"T5LxOrR6bjFY"},"source":["# Reading data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmnDoKifpFZ7"},"outputs":[],"source":["import pandas as pd\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOaGLl-Lbxjf"},"outputs":[],"source":["df_source_corpus=pd.read_csv('/content/drive/MyDrive/dlss24/source_corpus.csv')"]},{"cell_type":"code","source":["df_source_corpus = df_source_corpus.dropna(subset=['text'])"],"metadata":{"id":"V1zJsjYHxx77"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1JiJSClKR2M"},"outputs":[],"source":["df_source_corpus.head()"]},{"cell_type":"code","source":["\n"],"metadata":{"id":"PQKMyozRLKTz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Word2vec\n","\n","[Image of word2vec 1-hidden layer NN](https://becominghuman.ai/mathematical-introduction-to-glove-word-embedding-60f24154e54c)\n","\n","Word2vec creates vectors that represent the context of words, while GloVe creates vectors that represent the co-occurrence of words.\n","\n","Word2vec uses a shallow neural network to create vectors, while GloVe uses a global matrix factorization technique\n","\n","\n","Word2vec requires a large amount of training data, while GloVe can be trained on smaller datasets. This makes GloVe more suitable for smaller tasks, while Word2vec is better suited for larger applications."],"metadata":{"id":"jgYz_Kq2sd8x"}},{"cell_type":"code","source":["# word2vec requires sentences as input\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from string import punctuation\n","translator = str.maketrans('','',punctuation)\n","from nltk.corpus import stopwords\n","stoplist = set(stopwords.words('english'))\n","from nltk.stem import SnowballStemmer\n","stemmer = SnowballStemmer('english')"],"metadata":{"id":"x_LiEdoZshp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#from previous class\n","def normalize_text(doc):\n","    \"Input doc and return clean list of tokens\"\n","    doc = doc.replace('\\r', ' ').replace('\\n', ' ')\n","    lower = doc.lower() # all lower case\n","    nopunc = lower.translate(translator) # remove punctuation\n","    words = nopunc.split() # split into tokens\n","    nostop = [w for w in words if w not in stoplist] # remove stopwords\n","    no_numbers = [w if not w.isdigit() else '#' for w in nostop] # normalize numbers\n","    stemmed = [stemmer.stem(w) for w in no_numbers] # stem each word\n","    return stemmed"],"metadata":{"id":"McKq2yIqslqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> 1. Apply the normalize_text function to the data (df_source_corpus)\n","2. Train word2vec on all of the data (All that is required is that the input yields one sentence (list of utf8 words) after another.)\n","\n"],"metadata":{"id":"tOQZ7jdpyECO"}},{"cell_type":"code","source":[],"metadata":{"id":"_9vEJPOaRHbt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QxSXPBV-RHZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Um4uhXZ9RHWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"baJHXy5NRHTn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> 1. Look for the word vectors for immigration, economy, security and rights\n","2. See which of these (economy, security and rights) is closer to immigration\n","\n","Try w2v.wv.\n","\n"],"metadata":{"id":"pAi5kOetjPYT"}},{"cell_type":"code","source":[],"metadata":{"id":"suANhb-SRKk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3BjjMCSvRKaX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_qd2rxcjRKTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nq9n_4ppRKQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pOlYUFo_RKNv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> Analogies with the dataset:\n","1. Scientist is to man as __ is to woman\n","2. Scientist is to woman as __ is to man\n","\n"],"metadata":{"id":"pFmF2Otwj_ku"}},{"cell_type":"code","source":[],"metadata":{"id":"v1O1OG16RLUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ag9NHqcMRLOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IlV1sqxHRLLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bgJwJXwSRLIU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GLove\n","\n"],"metadata":{"id":"GcaseSp126K2"}},{"cell_type":"markdown","source":["\n","\n","> Train Glove on your dataset and check most similar words to environment\n","\n"],"metadata":{"id":"qLaY8FBqpTqW"}},{"cell_type":"code","source":["!pip install glove-python3"],"metadata":{"id":"RqCdsLVb3UV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import itertools\n","from glove import Corpus, Glove"],"metadata":{"id":"CAB9XU2c3Bpc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus = Corpus()\n","corpus.fit(sentences_normalized, window=10)\n","glove = Glove(no_components=100, learning_rate=0.05)"],"metadata":{"id":"f3Jox1Tc273w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n","glove.add_dictionary(corpus.dictionary)"],"metadata":{"id":"6tB7T1gO3z4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove.word_vectors[glove.dictionary['environment']].shape"],"metadata":{"id":"CXBikr0kpgKB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove.word_vectors[glove.dictionary['environment']]"],"metadata":{"id":"aqkLH5Xy3uZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove.most_similar('environment')"],"metadata":{"id":"EeriekgC3yP8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","# 2017: Attention is all you need\n","\n"],"metadata":{"id":"eHP6ewXACXpC"}},{"cell_type":"code","source":["# Attention Basically\n","import numpy as np\n","\n","class Node:\n","\n","  def __init__(self):\n","\n","    # the vector stored at this node (what is learned, the output of the layer)\n","    self.data=np.random.randn(20)\n","\n","    # weights governing how this node interacts with other nodes\n","    self.wkey = np.random.randn(20, 20)\n","    self.wquery = np.random.randn(20, 20)\n","    self.wvalue = np.random.randn(20, 20)\n","\n","  def key(self):\n","    # what do I have?\n","    return self.wkey @ self.data\n","\n","  def query(self):\n","    # what am I looking for? (next work is the text shift by 1, classification is the class)\n","    return self.wquery @ self.data\n","\n","  def value(self):\n","    # what do I oublicly reveal to others?\n","    return self.wvalue @ self.data\n"],"metadata":{"id":"l6oXzqVbCXRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Graph:\n","\n","  def __init__(self):\n","    # make 10 nodes\n","    self.nodes=[Node() for _ in range(10)]\n","    #make 40 edges\n","    randi=lambda: np.random.randint(len(self.nodes))\n","    self.edges=[[randi(),randi()] for _ in range(40)]\n","\n","  def run(self):\n","\n","    updates=[]\n","    for i,n in enumerate(self.nodes):\n","\n","      #what is the node looking for?\n","      q=n.query()\n","\n","      #find all edges that are input to this node\n","      inputs = [self.nodes[ifrom] for (ifrom, ito) in self.edges if ito==i]\n","      if len(inputs)==0:\n","        continue #ignore, next in for loop\n","      # gather keys, i.e what they hold\n","      keys=[m.key() for m in inputs]\n","      #calculate compatibilities: dot product of  key with query\n","      scores=[k.dot(q) for k in keys]\n","      #softmax them so they sum to 1\n","      scores=np.exp(scores)\n","      scores=scores/np.sum(scores)\n","      # gather the appropriate values with weighted sum\n","      values=[m.value() for m in inputs]\n","      update=sum([s*v for s,v in zip(scores, values)])\n","      updates.append(update)\n","\n","    for n,u in zip(self.nodes, updates):\n","      n.data=n.data +u #residual connection"],"metadata":{"id":"LK4Nz5KYEa_L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xk4SNQfuIbn0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> 1. Create a Graph\n","2. Print the key, value and query for the 4th node\n","3. Print the data before running and after running\n","\n"],"metadata":{"id":"Q118hX6lIrPl"}},{"cell_type":"code","source":[],"metadata":{"id":"c4yTzX1IQhQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k-jzsaiBQhNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"neHQKNaiQhKO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Transformers from scratch\n","\n","[Documentation](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html)"],"metadata":{"id":"eNN6CACNJHPr"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math"],"metadata":{"id":"7aMFni29OkMm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the scaled dot-product function\n","def scaled_dot_product(q, k, v, mask=None):\n","    d_k = q.size()[-1]\n","    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n","    attn_logits = attn_logits / math.sqrt(d_k)\n","    if mask is not None:\n","        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n","    attention = F.softmax(attn_logits, dim=-1)\n","    values = torch.matmul(attention, v)\n","    return values, attention\n","\n","# Define the expand mask function\n","def expand_mask(mask):\n","    assert mask.ndim >= 2, \"Mask must be at least 2-dimensional with seq_length x seq_length\"\n","    if mask.ndim == 3:\n","        mask = mask.unsqueeze(1)\n","    while mask.ndim < 4:\n","        mask = mask.unsqueeze(0)\n","    return mask"],"metadata":{"id":"zUxmTfWCOpH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the MultiheadAttention class\n","class MultiheadAttention(nn.Module):\n","    def __init__(self, input_dim, embed_dim, num_heads):\n","        super().__init__()\n","        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.head_dim = embed_dim // num_heads\n","        self.qkv_proj = nn.Linear(input_dim, 3 * embed_dim)\n","        self.o_proj = nn.Linear(embed_dim, embed_dim)\n","        self._reset_parameters()\n","\n","    def _reset_parameters(self):\n","        nn.init.xavier_uniform_(self.qkv_proj.weight)\n","        self.qkv_proj.bias.data.fill_(0)\n","        nn.init.xavier_uniform_(self.o_proj.weight)\n","        self.o_proj.bias.data.fill_(0)\n","\n","    def forward(self, x, mask=None, return_attention=False):\n","        batch_size, seq_length, _ = x.size()\n","        if mask is not None:\n","            mask = expand_mask(mask)\n","        qkv = self.qkv_proj(x)\n","        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3 * self.head_dim)\n","        qkv = qkv.permute(0, 2, 1, 3)\n","        q, k, v = qkv.chunk(3, dim=-1)\n","        values, attention = scaled_dot_product(q, k, v, mask=mask)\n","        values = values.permute(0, 2, 1, 3).reshape(batch_size, seq_length, self.embed_dim)\n","        o = self.o_proj(values)\n","        if return_attention:\n","            return o, attention\n","        else:\n","            return o\n","\n","# Define the EncoderBlock class\n","class EncoderBlock(nn.Module):\n","    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n","        super().__init__()\n","        self.self_attn = MultiheadAttention(input_dim, input_dim, num_heads)\n","        self.linear_net = nn.Sequential(\n","            nn.Linear(input_dim, dim_feedforward),\n","            nn.Dropout(dropout),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(dim_feedforward, input_dim)\n","        )\n","        self.norm1 = nn.LayerNorm(input_dim)\n","        self.norm2 = nn.LayerNorm(input_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        attn_out = self.self_attn(x, mask=mask)\n","        x = x + self.dropout(attn_out)\n","        x = self.norm1(x)\n","        linear_out = self.linear_net(x)\n","        x = x + self.dropout(linear_out)\n","        x = self.norm2(x)\n","        return x\n","\n","# Define the TransformerEncoder class\n","class TransformerEncoder(nn.Module):\n","    def __init__(self, num_layers, **block_args):\n","        super().__init__()\n","        self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(num_layers)])\n","\n","    def forward(self, x, mask=None):\n","        for l in self.layers:\n","            x = l(x, mask=mask)\n","        return x\n","\n","    def get_attention_maps(self, x, mask=None):\n","        attention_maps = []\n","        for l in self.layers:\n","            _, attn_map = l.self_attn(x, mask=mask, return_attention=True)\n","            attention_maps.append(attn_map)\n","            x = l(x)\n","        return attention_maps\n","\n","# Define the PositionalEncoding class\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe, persistent=False)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:, :x.size(1)]\n","        return x\n","\n","\n"],"metadata":{"id":"yXSNrmYyJJVq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the Transformer-based text classifier\n","class TransformerClassifier(nn.Module):\n","    def __init__(self, vocab_size, d_model, num_heads, num_layers, dim_feedforward, num_classes, max_len=5000, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.encoder = TransformerEncoder(\n","            num_layers=num_layers,\n","            input_dim=d_model,\n","            num_heads=num_heads,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout\n","        )\n","        self.pre_classifier = nn.Linear(d_model, d_model)\n","        self.classifier = nn.Linear(d_model, num_classes)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input_ids, mask=None):\n","        x = self.embedding(input_ids)\n","        x = self.positional_encoding(x)\n","        x = self.encoder(x, mask=mask)\n","        x = x[:, 0]  # Use the [CLS] token (first token) for classification\n","        x = F.relu(self.pre_classifier(x))\n","        x = self.dropout(x)\n","        logits = self.classifier(x)\n","        return logits\n"],"metadata":{"id":"pa2X_-W6O1BL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Example usage\n","vocab_size = 30522  # Vocabulary size (BERT's vocab size)\n","d_model = 768  # Embedding size\n","num_heads = 12  # Number of attention heads\n","num_layers = 6  # Number of transformer layers\n","dim_feedforward = 3072  # Feedforward network hidden size\n","num_classes = 2  # Number of output classes (e.g., binary classification)\n","max_len = 512  # Maximum sequence length\n","dropout = 0.1  # Dropout rate\n","\n","model = TransformerClassifier(vocab_size, d_model, num_heads, num_layers, dim_feedforward, num_classes, max_len, dropout)\n","\n","# Assume we have a tokenizer that converts sentences to input_ids\n","# For demonstration, using random input_ids\n","input_ids = torch.randint(0, vocab_size, (1, max_len))  # Batch size 1, sequence length max_len\n","mask = (input_ids != 0).unsqueeze(1).unsqueeze(2)  # Mask for non-padding tokens\n","\n","logits = model(input_ids, mask)\n","print(logits)"],"metadata":{"id":"5EGiWisKO4DQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mask.shape"],"metadata":{"id":"0sMeqFc6PjkF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#batch size, seq length\n","input_ids.shape\n","\n","\n","#In the attention mechanism,\n","#the mask needs to be broadcastable to the shape [batch_size, num_heads, seq_length, seq_length]\n","#[batch_size, 1, seq_length, seq_length]: the num_heads will be matched in the code by the number of heads"],"metadata":{"id":"RcKvWciHPtmh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Transformers: Hugging Face\n","\n","[Hugging Face](https://huggingface.co/docs/transformers/main_classes/tokenizer)"],"metadata":{"id":"LmhLfblw52Xf"}},{"cell_type":"code","source":["#!pip install transformers\n","import torch\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n","\n","# gpu or cpu?\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print (device)"],"metadata":{"id":"WWNSmGAR4qlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name = 'distilbert-base-uncased' # huggingface model_ID or path to folder\n","model = DistilBertForSequenceClassification.from_pretrained(model_name)\n","print (model)"],"metadata":{"id":"fWibqqkV55fv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> Apply that to our dataset\n","\n"],"metadata":{"id":"KkjQopMgQn4q"}},{"cell_type":"code","source":[],"metadata":{"id":"QQOP3CxaQngY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> Manifesto Berta\n","\n","[Documentation](https://manifesto-project.wzb.eu/information/documents/manifestoberta)\n","\n"],"metadata":{"id":"knnoJW4D9eVv"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"manifesto-project/manifestoberta-xlm-roberta-56policy-topics-sentence-2023-1-1\")\n","tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n","\n","sentence = \"We will restore funding to the Global Environment Facility and the Intergovernmental Panel on Climate Change, to support critical climate science research around the world\"\n","\n","inputs = tokenizer(sentence,\n","                   return_tensors=\"pt\",\n","                   max_length=200,  #we limited the input to 200 tokens during finetuning\n","                   padding=\"max_length\",\n","                   truncation=True\n","                   )\n","\n","logits = model(**inputs).logits\n","\n","probabilities = torch.softmax(logits, dim=1).tolist()[0]\n","probabilities = {model.config.id2label[index]: round(probability * 100, 2) for index, probability in enumerate(probabilities)}\n","probabilities = dict(sorted(probabilities.items(), key=lambda item: item[1], reverse=True))\n","print(probabilities)\n","# {'501 - Environmental Protection: Positive': 67.28, '411 - Technology and Infrastructure': 15.19, '107 - Internationalism: Positive': 13.63, '416 - Anti-Growth Economy: Positive': 2.02...\n","\n","predicted_class = model.config.id2label[logits.argmax().item()]\n","print(predicted_class)\n","# 501 - Environmental Protection: Positive\n"],"metadata":{"id":"YgH0DoHb9g0S"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPm+dLF3v4xCxF5vSse63n/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}